{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Group 13 | Aditya Sharma, Adarsh Balan, Thaneshwar Prasad Sahu, Muhammad Ashraf Hussain, Prathyusha Thatipelli\n",
        "Part B | Question 1 and 2"
      ],
      "metadata": {
        "id": "VzA0ZosveSmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWSbS4tMIr2f",
        "outputId": "6623f6a8-7794-4035-e464-6a46f6fafc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connecting to Google Collab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "ZqR36E5lKmGR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Function to extract zip file\n",
        "def extract_zip(file_path, extract_to):\n",
        "    with ZipFile(file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted to {extract_to}\")"
      ],
      "metadata": {
        "id": "NtnJ-wHJKmQ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Function to split dataset into train and test\n",
        "def split_dataset(dataset_path, train_dir, test_dir):\n",
        "    categories = os.listdir(dataset_path)\n",
        "    categories.sort()\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        images = sorted(os.listdir(category_path))\n",
        "\n",
        "        # Creating directories for train and test sets\n",
        "        train_category_dir = os.path.join(train_dir, category)\n",
        "        test_category_dir = os.path.join(test_dir, category)\n",
        "        os.makedirs(train_category_dir, exist_ok=True)\n",
        "        os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "        # Splitting and copying files\n",
        "        for i, img in enumerate(images):\n",
        "            src_path = os.path.join(category_path, img)\n",
        "            if i < 40:  # First 40 images for training\n",
        "                shutil.copy(src_path, train_category_dir)\n",
        "            else:  # Remaining images for testing\n",
        "                shutil.copy(src_path, test_category_dir)\n",
        "\n",
        "    print(f\"Training and testing datasets created at {train_dir} and {test_dir}\")"
      ],
      "metadata": {
        "id": "ZN3xqBN7KmXs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Files Paths\n",
        "zip_file_path = '/content/drive/MyDrive/AAI Group Assignment/dataset.zip'\n",
        "extract_to = '/content/drive/MyDrive/AAI Group Assignment/dataset'\n",
        "train_dir = '/content/drive/MyDrive/AAI Group Assignment/train'\n",
        "test_dir = '/content/drive/MyDrive/AAI Group Assignment/test'\n",
        "\n",
        "# Extracting images dataset\n",
        "extract_zip(zip_file_path, extract_to)\n",
        "\n",
        "# Check the contents of the extracted directory\n",
        "print(\"Contents of extracted directory:\", os.listdir(extract_to))\n",
        "\n",
        "# Splitting dataset\n",
        "split_dataset(os.path.join(extract_to, 'dataset'), train_dir, test_dir)\n",
        "\n",
        "# Check the contents of the train and test directories\n",
        "print(\"Contents of train directory:\", os.listdir(train_dir))\n",
        "print(\"Contents of test directory:\", os.listdir(test_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ6tPLFUJF_8",
        "outputId": "609e7c44-d3e9-4ba1-ede6-d7b965f2074e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to /content/drive/MyDrive/AAI Group Assignment/dataset\n",
            "Contents of extracted directory: ['dataset']\n",
            "Training and testing datasets created at /content/drive/MyDrive/AAI Group Assignment/train and /content/drive/MyDrive/AAI Group Assignment/test\n",
            "Contents of train directory: ['accordion', 'bass', 'camera', 'crocodile', 'crocodile_head', 'cup', 'dollar_bill', 'emu', 'gramophone', 'hedgehog', 'nautilus', 'pizza', 'pyramid', 'sea_horse', 'windsor_chair']\n",
            "Contents of test directory: ['accordion', 'bass', 'camera', 'crocodile', 'crocodile_head', 'cup', 'dollar_bill', 'emu', 'gramophone', 'hedgehog', 'nautilus', 'pizza', 'pyramid', 'sea_horse', 'windsor_chair']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report"
      ],
      "metadata": {
        "id": "8pPuQnYtNHib"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lGkkXSnlNHlQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "_fTsrRR8NHqQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/AAI Group Assignment/train', transform=transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/AAI Group Assignment/test', transform=transform)"
      ],
      "metadata": {
        "id": "fuNORe-rNHuR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3wTp5gtZNHxm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining models to train\n",
        "models_to_train = {\n",
        "    'resnet18': models.resnet18(pretrained=True),\n",
        "    'densenet121': models.densenet121(pretrained=True),\n",
        "    'vgg19': models.vgg19(pretrained=True)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCr8v8byNH1c",
        "outputId": "bce6baf6-d1f9-40fd-c4e2-ef97bd0394e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 147MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 127MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:04<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying the last layer for 15 classes\n",
        "for model_name, model in models_to_train.items():\n",
        "    if 'resnet' in model_name:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = torch.nn.Linear(num_ftrs, 15)\n",
        "    elif 'vgg' in model_name:\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = torch.nn.Linear(num_ftrs, 15)\n",
        "    elif 'densenet' in model_name:\n",
        "        num_ftrs = model.classifier.in_features\n",
        "        model.classifier = torch.nn.Linear(num_ftrs, 15)\n",
        "    model.to(device)"
      ],
      "metadata": {
        "id": "RUZ29f3nNurJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Training and evaluation function\n",
        "def train_and_evaluate(model, train_loader, test_loader, device):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average=None)\n",
        "    recall = recall_score(all_labels, all_preds, average=None)\n",
        "    return precision, recall"
      ],
      "metadata": {
        "id": "EtzJwxOANuuL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluating each model\n",
        "num_epochs = 25\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models_to_train.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    precision, recall = train_and_evaluate(model, train_loader, test_loader, device)\n",
        "    results[model_name] = {\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymKNSadbNuxT",
        "outputId": "1cf36a78-e16c-42ea-882f-3c4f074b6416"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating resnet18...\n",
            "Epoch 1/25, Loss: 0.14063434302806854\n",
            "Epoch 2/25, Loss: 0.057409320026636124\n",
            "Epoch 3/25, Loss: 0.06868451833724976\n",
            "Epoch 4/25, Loss: 0.037219174206256866\n",
            "Epoch 5/25, Loss: 0.028178133070468903\n",
            "Epoch 6/25, Loss: 0.06909924000501633\n",
            "Epoch 7/25, Loss: 0.026505939662456512\n",
            "Epoch 8/25, Loss: 0.02454829216003418\n",
            "Epoch 9/25, Loss: 0.031990908086299896\n",
            "Epoch 10/25, Loss: 0.022165261209011078\n",
            "Epoch 11/25, Loss: 0.02897891402244568\n",
            "Epoch 12/25, Loss: 0.01501509826630354\n",
            "Epoch 13/25, Loss: 0.02373841218650341\n",
            "Epoch 14/25, Loss: 0.018202783539891243\n",
            "Epoch 15/25, Loss: 0.020262477919459343\n",
            "Epoch 16/25, Loss: 0.040584344416856766\n",
            "Epoch 17/25, Loss: 0.015272463671863079\n",
            "Epoch 18/25, Loss: 0.017581652849912643\n",
            "Epoch 19/25, Loss: 0.011857635341584682\n",
            "Epoch 20/25, Loss: 0.011391010135412216\n",
            "Epoch 21/25, Loss: 0.011890620924532413\n",
            "Epoch 22/25, Loss: 0.01605450175702572\n",
            "Epoch 23/25, Loss: 0.008651270531117916\n",
            "Epoch 24/25, Loss: 0.022066481411457062\n",
            "Epoch 25/25, Loss: 0.012296359986066818\n",
            "Training and evaluating densenet121...\n",
            "Epoch 1/25, Loss: 0.08740967512130737\n",
            "Epoch 2/25, Loss: 0.028316093608736992\n",
            "Epoch 3/25, Loss: 0.06206175684928894\n",
            "Epoch 4/25, Loss: 0.04529522359371185\n",
            "Epoch 5/25, Loss: 0.021236605942249298\n",
            "Epoch 6/25, Loss: 0.023629480972886086\n",
            "Epoch 7/25, Loss: 0.011831761337816715\n",
            "Epoch 8/25, Loss: 0.024832041934132576\n",
            "Epoch 9/25, Loss: 0.044277623295784\n",
            "Epoch 10/25, Loss: 0.016931651160120964\n",
            "Epoch 11/25, Loss: 0.015888331457972527\n",
            "Epoch 12/25, Loss: 0.008100301958620548\n",
            "Epoch 13/25, Loss: 0.013920933939516544\n",
            "Epoch 14/25, Loss: 0.029740264639258385\n",
            "Epoch 15/25, Loss: 0.013623036444187164\n",
            "Epoch 16/25, Loss: 0.010365628637373447\n",
            "Epoch 17/25, Loss: 0.007874789647758007\n",
            "Epoch 18/25, Loss: 0.015897197648882866\n",
            "Epoch 19/25, Loss: 0.0119498111307621\n",
            "Epoch 20/25, Loss: 0.009250419214367867\n",
            "Epoch 21/25, Loss: 0.01770429126918316\n",
            "Epoch 22/25, Loss: 0.016909828409552574\n",
            "Epoch 23/25, Loss: 0.020906632766127586\n",
            "Epoch 24/25, Loss: 0.030112646520137787\n",
            "Epoch 25/25, Loss: 0.030381230637431145\n",
            "Training and evaluating vgg19...\n",
            "Epoch 1/25, Loss: 0.002315773628652096\n",
            "Epoch 2/25, Loss: 0.0007475065067410469\n",
            "Epoch 3/25, Loss: 0.00016324575699400157\n",
            "Epoch 4/25, Loss: 0.0002515343076083809\n",
            "Epoch 5/25, Loss: 6.392181239789352e-05\n",
            "Epoch 6/25, Loss: 0.00021703507809434086\n",
            "Epoch 7/25, Loss: 0.0007854479481466115\n",
            "Epoch 8/25, Loss: 6.370686605805531e-05\n",
            "Epoch 9/25, Loss: 0.00020656462584156543\n",
            "Epoch 10/25, Loss: 2.7972355383099057e-05\n",
            "Epoch 11/25, Loss: 0.0003426851471886039\n",
            "Epoch 12/25, Loss: 9.86254817689769e-05\n",
            "Epoch 13/25, Loss: 0.0008384441025555134\n",
            "Epoch 14/25, Loss: 0.003664429998025298\n",
            "Epoch 15/25, Loss: 0.0004360201710369438\n",
            "Epoch 16/25, Loss: 0.0013736592372879386\n",
            "Epoch 17/25, Loss: 0.000646266620606184\n",
            "Epoch 18/25, Loss: 1.427945517207263e-05\n",
            "Epoch 19/25, Loss: 0.0010791533859446645\n",
            "Epoch 20/25, Loss: 0.00022229035675991327\n",
            "Epoch 21/25, Loss: 0.00018855281814467162\n",
            "Epoch 22/25, Loss: 3.391576683497988e-05\n",
            "Epoch 23/25, Loss: 0.004325329791754484\n",
            "Epoch 24/25, Loss: 6.295423372648656e-05\n",
            "Epoch 25/25, Loss: 0.011011590249836445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names\n",
        "class_names = train_dataset.classes"
      ],
      "metadata": {
        "id": "6EsDqJQjWXIt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results with class names\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Per-class Precision and Recall:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"{class_name}: Precision - {metrics['precision'][i]:.4f}, Recall - {metrics['recall'][i]:.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwdl1kpGWrI5",
        "outputId": "12e96518-a9d7-4d5a-d80e-3581486d1bce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: resnet18\n",
            "Per-class Precision and Recall:\n",
            "accordion: Precision - 1.0000, Recall - 1.0000\n",
            "bass: Precision - 1.0000, Recall - 1.0000\n",
            "camera: Precision - 1.0000, Recall - 1.0000\n",
            "crocodile: Precision - 0.8000, Recall - 0.8000\n",
            "crocodile_head: Precision - 0.8182, Recall - 0.8182\n",
            "cup: Precision - 1.0000, Recall - 1.0000\n",
            "dollar_bill: Precision - 1.0000, Recall - 1.0000\n",
            "emu: Precision - 1.0000, Recall - 1.0000\n",
            "gramophone: Precision - 1.0000, Recall - 1.0000\n",
            "hedgehog: Precision - 0.9333, Recall - 1.0000\n",
            "nautilus: Precision - 1.0000, Recall - 1.0000\n",
            "pizza: Precision - 1.0000, Recall - 1.0000\n",
            "pyramid: Precision - 1.0000, Recall - 1.0000\n",
            "sea_horse: Precision - 1.0000, Recall - 0.9412\n",
            "windsor_chair: Precision - 1.0000, Recall - 1.0000\n",
            "\n",
            "Model: densenet121\n",
            "Per-class Precision and Recall:\n",
            "accordion: Precision - 1.0000, Recall - 1.0000\n",
            "bass: Precision - 1.0000, Recall - 1.0000\n",
            "camera: Precision - 1.0000, Recall - 1.0000\n",
            "crocodile: Precision - 0.9000, Recall - 0.9000\n",
            "crocodile_head: Precision - 0.9091, Recall - 0.9091\n",
            "cup: Precision - 1.0000, Recall - 1.0000\n",
            "dollar_bill: Precision - 1.0000, Recall - 1.0000\n",
            "emu: Precision - 1.0000, Recall - 1.0000\n",
            "gramophone: Precision - 1.0000, Recall - 1.0000\n",
            "hedgehog: Precision - 0.9286, Recall - 0.9286\n",
            "nautilus: Precision - 0.9375, Recall - 1.0000\n",
            "pizza: Precision - 1.0000, Recall - 1.0000\n",
            "pyramid: Precision - 1.0000, Recall - 1.0000\n",
            "sea_horse: Precision - 1.0000, Recall - 0.9412\n",
            "windsor_chair: Precision - 1.0000, Recall - 1.0000\n",
            "\n",
            "Model: vgg19\n",
            "Per-class Precision and Recall:\n",
            "accordion: Precision - 1.0000, Recall - 1.0000\n",
            "bass: Precision - 1.0000, Recall - 1.0000\n",
            "camera: Precision - 1.0000, Recall - 1.0000\n",
            "crocodile: Precision - 0.7500, Recall - 0.9000\n",
            "crocodile_head: Precision - 0.9000, Recall - 0.8182\n",
            "cup: Precision - 1.0000, Recall - 0.8824\n",
            "dollar_bill: Precision - 0.9231, Recall - 1.0000\n",
            "emu: Precision - 1.0000, Recall - 1.0000\n",
            "gramophone: Precision - 1.0000, Recall - 1.0000\n",
            "hedgehog: Precision - 1.0000, Recall - 0.9286\n",
            "nautilus: Precision - 0.9375, Recall - 1.0000\n",
            "pizza: Precision - 1.0000, Recall - 1.0000\n",
            "pyramid: Precision - 1.0000, Recall - 0.9412\n",
            "sea_horse: Precision - 0.9412, Recall - 0.9412\n",
            "windsor_chair: Precision - 0.9412, Recall - 1.0000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}